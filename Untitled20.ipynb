{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOw8hNVojls9SWxm2kD619x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunmulim/-/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSq8LLJgu5WL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_noise(x, scale=0.5):\n",
        "\n",
        "     noise = np.random.normal(\n",
        "        loc=0,\n",
        "        scale=0.5,\n",
        "        size=x.shape\n",
        "     )\n",
        "     noise_x = x + noise\n",
        "\n",
        "     noise_x = np.clip(noise_x, 0, 1)\n",
        "     noise_x = torch.Tensor(noise_x)\n",
        "     noise_x = noise_x.type(torch.FloatTensor)\n",
        "     return noise_x"
      ],
      "metadata": {
        "id": "oSe9liqEu817"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_dataset = MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "img = training_dataset.data[0]\n",
        "\n",
        "noise_img = gaussian_noise(img)\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"original\")\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"noisy\")\n",
        "plt.imshow(noise_img, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "l170JNKiu-d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "\n",
        "class Denoising(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.mnist = MNIST(\n",
        "            root=\"./data\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=ToTensor()\n",
        "        )\n",
        "        self.noise_data = []\n",
        "\n",
        "\n",
        "        for i in range(len(self.mnist)):\n",
        "            noise_x = gaussian_noise(self.mnist.data[i])\n",
        "            noise_x = torch.tensor(noise_x)\n",
        "            self.noise_data.append(torch.unsqueeze(noise_x, dim=0))\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.noise_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.noise_data[idx]\n",
        "        label = self.mnist.data[idx] / 255\n",
        "\n",
        "        return data, label"
      ],
      "metadata": {
        "id": "E-ah5MICvCFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Denoising()"
      ],
      "metadata": {
        "id": "eZebIVxqvET7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0][0].shape, train_dataset[0][1].shape)"
      ],
      "metadata": {
        "id": "6eKMmbQGvGgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels,\n",
        "            hidden_dim,\n",
        "            kernel_size=3,\n",
        "\n",
        "            padding=1\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            hidden_dim,\n",
        "            out_channels,\n",
        "            kernel_size=3,\n",
        "\n",
        "            padding=1\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "6tMBeO21vILs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BasicBlock(1, 16, hidden_dim=8)"
      ],
      "metadata": {
        "id": "4r1jK9NSvJrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.block1 = BasicBlock(in_channels=1, out_channels=16, hidden_dim=16)\n",
        "        self.block2 = BasicBlock(in_channels=16, out_channels=8, hidden_dim=8)\n",
        "\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "SLbzjF0HvN1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder()"
      ],
      "metadata": {
        "id": "NS_Q_VOMvP3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.block1 = BasicBlock(in_channels=8, out_channels=8, hidden_dim=8)\n",
        "        self.block2 = BasicBlock(in_channels=8, out_channels=16, hidden_dim=16)\n",
        "\n",
        "        self.output_conv = nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, padding=1)\n",
        "\n",
        "        self.upsample1 = nn.ConvTranspose2d(8, 8, kernel_size=2, stride=2)\n",
        "        self.upsample2 = nn.ConvTranspose2d(16, 16, kernel_size=2, stride=2)\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.upsample1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.upsample2(x)\n",
        "        x = self.output_conv(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "aO6SmDn8vSrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Decoder()"
      ],
      "metadata": {
        "id": "Z7y28T2-vTwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CAE, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "oQ6gTMdEvWGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CAE()"
      ],
      "metadata": {
        "id": "LCVOMJK0vXva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "train_dataset = Denoising()\n",
        "train_loader = DataLoader(train_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "tPDH9EuHvZWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CAE().cuda()\n",
        "\n",
        "\n",
        "lr = 0.001\n",
        "optim = Adam(params=model.parameters(), lr=lr)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    iterator = tqdm.tqdm(train_loader)\n",
        "\n",
        "    for inputs, labels in iterator:\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        optim.zero_grad()\n",
        "        pred = model(inputs)\n",
        "        loss = criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        iterator.set_description(f\"[Epoch {epoch + 1}] loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "KDtweGhHvbhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), \"./CAE.pt\")"
      ],
      "metadata": {
        "id": "c8dxW8e0vk1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load(\"./CAE.pt\"))\n",
        "model = model.cuda()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    img = test_dataset.data[0]\n",
        "    noise_img = gaussian_noise(img)\n",
        "\n",
        "    input = torch.unsqueeze(noise_img, dim=0)\n",
        "    input.type(torch.FloatTensor)\n",
        "    input = input.cuda()\n",
        "    input = torch.unsqueeze(input, dim=0)\n",
        "\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(torch.squeeze(noise_img), cmap=\"gray\")\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(torch.squeeze(model(input).cpu()), cmap=\"gray\")\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(torch.squeeze(img), cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lARdarXjvpVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}